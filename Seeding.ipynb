{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elephant-xyz/photo-meta-data-notebook/blob/main/Step_2_Seeding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome to the Elephant Oracle Notebook\n",
        "\n",
        "You've completed the setup and are ready to submit real estate data to the Elephant protocol. This notebook will transform your seed data into validated, blockchain-ready submissions.\n",
        "\n",
        "## What This Notebook Does\n",
        "\n",
        "This interactive notebook automates:\n",
        "- Converting seed data to lexicon format\n",
        "- Validating against Elephant schemas\n",
        "- Canonicalizing data for consistent hashing\n",
        "- Uploading to IPFS via Pinata\n",
        "- Preparing transaction data for blockchain submission\n",
        "\n",
        "## What You'll Do\n",
        "\n",
        "1. **Configure Pinata** (1 minute)\n",
        "   - Enter your JWT token\n",
        "\n",
        "2. **Transform Data** (2 minutes)\n",
        "   - Run conversion to lexicon format\n",
        "   - Auto-validate against [lexicon.elephant.xyz](https://lexicon.elephant.xyz/) schemas\n",
        "   - Generate canonical JSON\n",
        "\n",
        "3. **Upload to IPFS** (2 minutes)\n",
        "   - Submit validated data to IPFS\n",
        "   - Receive content identifiers (CIDs)\n",
        "\n",
        "4. **Prepare Submission** (1 minute)\n",
        "   - Generate upload-results.csv\n",
        "   - Download for oracle portal\n",
        "\n",
        "5. **Submit to Blockchain** (2 minutes)\n",
        "   - Visit oracle.elephant.xyz\n",
        "   - Upload results file\n",
        "   - Confirm MetaMask transactions\n",
        "\n",
        "## Your Impact\n",
        "\n",
        "Each submission contributes to consensus. When three oracles submit matching data hashes, the data becomes blockchain truth and participants receive vMahout governance tokens.\n",
        "\n",
        "Let's begin."
      ],
      "metadata": {
        "id": "ymU63KRRBDKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 1: Please enter your property parcel ID, address and request used to get this property (you can add as much as needed just insert property information then run the cell)\n",
        "import os\n",
        "parcel_id = \"30434108090030050\" # @param {\"type\":\"string\"}\n",
        "address = \"1605 S US highway 1 3E, Jupiter, FL 33477\" # @param {\"type\":\"string\"}\n",
        "request_method = \"GET\" # @param {\"type\":\"string\"}\n",
        "url = \"https://pbcpao.gov/Property/Details?parcelId=30434108090030050\" # @param {\"type\":\"string\"}\n",
        "County = \"palm beach\" # @param {\"type\":\"string\"}\n",
        "headers = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "os.environ[\"parcel_id\"] = parcel_id\n",
        "os.environ[\"address\"] = address\n",
        "os.environ[\"request_method\"] = request_method\n",
        "os.environ[\"url\"] = url\n",
        "os.environ[\"County\"] = County\n",
        "os.environ[\"headers\"] = headers\n",
        "\n",
        "\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "\n",
        "# Get data from Step 2 environment variables\n",
        "parcel_id = os.environ.get(\"parcel_id\", \"\")\n",
        "address = os.environ.get(\"address\", \"\")\n",
        "request_method = os.environ.get(\"request_method\", \"\")\n",
        "url = os.environ.get(\"url\", \"\")\n",
        "county = os.environ.get(\"County\", \"\")\n",
        "headers = os.environ.get(\"headers\", \"\")\n",
        "\n",
        "\n",
        "def is_empty_value(value):\n",
        "    \"\"\"Check if value is empty or None\"\"\"\n",
        "    if value is None:\n",
        "        return True\n",
        "    if isinstance(value, str) and value.strip() == \"\":\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def ensure_directory(file_path):\n",
        "    \"\"\"Ensure the directory for the file exists\"\"\"\n",
        "    directory = os.path.dirname(file_path)\n",
        "    if directory and not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "def extract_query_params_and_base_url(url):\n",
        "    \"\"\"Extract query parameters and base URL separately\"\"\"\n",
        "    if is_empty_value(url):\n",
        "        return None, None\n",
        "\n",
        "    try:\n",
        "        parsed_url = urlparse(url)\n",
        "\n",
        "        # Base URL without query parameters\n",
        "        base_url = f\"{parsed_url.scheme}://{parsed_url.netloc}{parsed_url.path}\"\n",
        "\n",
        "        # Query parameters as multiValueQueryString format (object of arrays)\n",
        "        query_params = parse_qs(parsed_url.query)\n",
        "        multi_value_query = dict(query_params) if query_params else None\n",
        "\n",
        "        return base_url, multi_value_query\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not parse URL: {e}\")\n",
        "        return url, None\n",
        "\n",
        "def create_parcel_folder(parcel_id, address, method, url, county, headers):\n",
        "    # Create folder name based on parcel_id\n",
        "    clean_parcel_id = re.sub(r\"[^\\w\\-_]\", \"_\", str(parcel_id))\n",
        "    folder_name = f\"output/{clean_parcel_id}\"\n",
        "    ensure_directory(folder_name + \"/\")\n",
        "\n",
        "    # Extract base URL and query parameters separately\n",
        "    base_url, multi_value_query = extract_query_params_and_base_url(url)\n",
        "\n",
        "    # Create unnormalized_address.json\n",
        "    unnormalized_address_data = {\n",
        "        \"full_address\": address if not is_empty_value(address) else None,\n",
        "        \"source_http_request\": {\n",
        "            \"method\": method if not is_empty_value(method) else None,\n",
        "            \"url\": base_url if not is_empty_value(base_url) else None,\n",
        "            \"multiValueQueryString\": multi_value_query\n",
        "        },\n",
        "        \"county_jurisdiction\": county if not is_empty_value(county) else None,\n",
        "        \"request_identifier\": parcel_id if not is_empty_value(parcel_id) else None,\n",
        "    }\n",
        "    if headers and not is_empty_value(headers):\n",
        "        unnormalized_address_data[\"source_http_request\"][\"headers\"] = headers\n",
        "\n",
        "    # Create property_seed.json\n",
        "    property_seed_data = {\n",
        "        \"parcel_id\": parcel_id if not is_empty_value(parcel_id) else None,\n",
        "        \"source_http_request\": {\n",
        "            \"method\": method if not is_empty_value(method) else None,\n",
        "            \"url\": base_url if not is_empty_value(base_url) else None,\n",
        "            \"multiValueQueryString\": multi_value_query\n",
        "        },\n",
        "        \"request_identifier\": parcel_id if not is_empty_value(parcel_id) else None,\n",
        "    }\n",
        "    if headers and not is_empty_value(headers):\n",
        "        property_seed_data[\"source_http_request\"][\"headers\"] = headers\n",
        "\n",
        "    # Create relationship_property_to_address.json\n",
        "    relationship_data = {\n",
        "        \"from\": {\"/\": \"./property_seed.json\"},\n",
        "        \"to\": {\"/\": \"./unnormalized_address.json\"}\n",
        "    }\n",
        "\n",
        "    # Create root schema\n",
        "    root_schema = {\n",
        "        \"label\": \"Seed\",\n",
        "        \"relationships\": {\"property_seed\": {\"/\": \"./relationship_property_to_address.json\"}},\n",
        "    }\n",
        "\n",
        "    # Write all JSON files\n",
        "    files_to_create = [\n",
        "        (f\"{folder_name}/unnormalized_address.json\", unnormalized_address_data),\n",
        "        (f\"{folder_name}/property_seed.json\", property_seed_data),\n",
        "        (f\"{folder_name}/relationship_property_to_address.json\", relationship_data),\n",
        "        (f\"{folder_name}/bafkreif7ywbjxu3s6jfi6ginvmsufeux3cd5eujuivg2y7tmqt2qk4rsoe.json\", root_schema),\n",
        "    ]\n",
        "\n",
        "    for filename, data_obj in files_to_create:\n",
        "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(data_obj, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    return folder_name, unnormalized_address_data, property_seed_data\n",
        "\n",
        "def process_input_data():\n",
        "    try:\n",
        "        # Validate required data\n",
        "        if is_empty_value(parcel_id):\n",
        "            print(\"‚ùå Error: parcel_id is required but not provided\")\n",
        "            return\n",
        "\n",
        "        # Show extracted URL components\n",
        "        base_url, multi_value_query = extract_query_params_and_base_url(url)\n",
        "\n",
        "        # Create parcel folder and files\n",
        "        folder_name, address_data, property_data = create_parcel_folder(\n",
        "            parcel_id, address, request_method, url, county, headers\n",
        "        )\n",
        "\n",
        "        print(f\"\\n‚úÖ property with parcel {parcel_id} added successfully\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error processing input data: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# Process the input data\n",
        "process_input_data()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "poWZ3I6pcFuN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d42e11e-8af0-4ac8-d1ae-4e6d309176b4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ property with parcel 30434108090030050 added successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Upload .env file\n",
        "\n",
        "\n",
        "| Variable Name           | Purpose                     |\n",
        "|-------------------------|-----------------------------|\n",
        "| `PINATA_JWT`     | Access to pinata key              |\n",
        "\n",
        "\n",
        "- Click the **folder icon** üìÇ in the left sidebar to open the file browser.\n",
        "- Then click the **\"Upload\"** button and choose your `.env` file.\n",
        "\n",
        "```env\n",
        "# example of .env file\n",
        "PINATA_JWT=xxxxx\n",
        "```\n"
      ],
      "metadata": {
        "id": "biGoVhci_XPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 3: Run to upload your files to the IPFS\n",
        "! pip3 install python-dotenv\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "load_dotenv()\n",
        "!npx -y @elephant-xyz/cli validate-and-upload output"
      ],
      "metadata": {
        "id": "_d6lTNn0Zefx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51a5c528-c075-4bc0-893c-f4c9a7f15ee6",
        "collapsed": true
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K\u001b[1m\u001b[34müêò Elephant Network CLI - Validate and Upload\u001b[39m\u001b[22m\n",
            "\n",
            "\u001b7\u001b[?25l\u001b[?7l\u001b[1GInitializing    |\u001b[36m‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\u001b[39m| 100% | 0/0 | Errors: 0 | Skipped: 0 | 0s | ETA: 0s\u001b[0K\u001b7\u001b[?25l\u001b[?7l\u001b[1GFetching Schemas |\u001b[36m‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\u001b[39m| 0% | 0/1 | Errors: 0 | Skipped: 0 | 0s | ETA: 0s\u001b[0K\u001b[1GFetching Schemas |\u001b[36m‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\u001b[39m| 100% | 1/1 | Errors: 0 | Skipped: 0 | 0s | ETA: 0s\u001b[0K\u001b[?25h\u001b[?7h\u001b8\n",
            "\u001b[1GProcessing Files |\u001b[36m‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\u001b[39m| 0% | 0/2 | Errors: 0 | Skipped: 0 | 0s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\u001b[39m| 0% | 0/2 | Errors: 0 | Skipped: 0 | 1s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\u001b[39m| 50% | 1/2 | Errors: 0 | Skipped: 0 | 1s | ETA: 1s\u001b[0K\u001b[1GInstalling/Updating Fact Sheet Tool |\u001b[36m‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\u001b[39m| 100% | 1/1 | Errors: 0 | Skipped: 0 | 20s | ETA: 0s\u001b[0K\u001b[1GGenerating HTML Files |\u001b[36m‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\u001b[39m| 100% | 1/1 | Errors: 0 | Skipped: 0 | 20s | ETA: 0s\u001b[0K\u001b[1GUploading HTML Files |\u001b[36m‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\u001b[39m| 0% | 0/2 | Errors: 0 | Skipped: 0 | 20s | ETA: NFs\u001b[0K\u001b[1GUploading HTML Files |\u001b[36m‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\u001b[39m| 0% | 0/2 | Errors: 0 | Skipped: 0 | 21s | ETA: NFs\u001b[0K\u001b[1GUploading HTML Files |\u001b[36m‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\u001b[39m| 50% | 1/2 | Errors: 0 | Skipped: 0 | 21s | ETA: 20s\u001b[0K\u001b[1GUploading HTML Files |\u001b[36m‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\u001b[39m| 100% | 2/2 | Errors: 0 | Skipped: 0 | 21s | ETA: 0s\u001b[0K\u001b[?25h\u001b[?7h\u001b8\n",
            "\u001b[32m\u001b[39m\n",
            "\u001b[32m‚úÖ Validation and upload process finished\u001b[39m\n",
            "\u001b[32m\u001b[39m\n",
            "\u001b[1müìä Final Report:\u001b[22m\n",
            "  Total files scanned:    2\n",
            "  Files skipped: 0\n",
            "  Processing/upload errors: 0\n",
            "  Successfully processed (validated & uploaded):  2\n",
            "  Total files handled:    2\n",
            "  Duration:               0s\n",
            "\n",
            "  Error report:   ./submit_errors.csv\n",
            "  Warning report: ./submit_warnings.csv\n",
            "  Upload results: upload-results.csv\n",
            "\u001b[1m\u001b[22m\n",
            "\u001b[1müåê Property Fact Sheet Links:\u001b[22m\n",
            "\u001b[90m  (Note: It may take a few minutes for pages to propagate through IPFS gateways)\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "  1. Directory: 52434205310037080\n",
            "     \u001b[36mhttp://dweb.link/ipfs/bafkreiemsdptymff47hu2hm7wacqlioj3coi63a626e4ybxcazqgli6omi\u001b[39m\n",
            "\n",
            "  2. Directory: 30434108090030050\n",
            "     \u001b[36mhttp://dweb.link/ipfs/bafkreifgulxszyyfhhn27t5cemy675qi3qe26iujdq2lh2pkqfxrk4wcpe\u001b[39m\n",
            "\n",
            "\u001b[1m\u001b[22m\n",
            "\u001b[1müìÑ All HTML links have been saved to: \u001b[32mupload-results.csv\u001b[39m\u001b[22m\n",
            "\u001b[90m  Please check this file for the complete list of property fact sheet URLs.\u001b[39m\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Submitting Your Data to the Blockchain\n",
        "\n",
        "### Submitting Your Data\n",
        "\n",
        "After running the upload command in the notebook:\n",
        "\n",
        "1. **Download your results file**\n",
        "   - The notebook will generate `upload-results.csv`\n",
        "   - This file contains your data hashes and IPFS CIDs\n",
        "   - Download it to your computer\n",
        "\n",
        "2. **Visit the Oracle Submission Portal**\n",
        "   - Go to https://oracle.elephant.xyz/\n",
        "   - Connect your MetaMask wallet when prompted\n",
        "   - Upload your `upload-results.csv` file\n",
        "\n",
        "3. **Submit transactions**\n",
        "   - The portal will read your CSV and prepare transactions\n",
        "   - Click \"Submit to Contract\" to begin\n",
        "   - MetaMask will pop up for each data entry\n",
        "   - Confirm each transaction (small gas fee applies)\n",
        "   - Wait for confirmations between submissions\n",
        "\n",
        "Once complete, your data is permanently recorded on the blockchain. You'll receive vMahout tokens as rewards after consensus is reached (when 3 different oracles submit matching data hashes)."
      ],
      "metadata": {
        "id": "8CYSslk1Zx1-"
      }
    }
  ]
}
