{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elephant-xyz/notebook/blob/main/Mining_County.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUcGqCQnZW9r"
      },
      "source": [
        "#County Mining process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PI_XjroKd45G"
      },
      "outputs": [],
      "source": [
        "# @title Step 1: Upload .env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Btx2OEDfVtG",
        "outputId": "ab1724cd-010f-4858-8053-a9c7d894b0e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✔ seed-results.csv extracted to seed.csv\n",
            "✔ seed-results.csv extracted to seed-results.csv\n"
          ]
        }
      ],
      "source": [
        "# @title Step 2: Upload seed_output.zip\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def extract_seed_results(zip_path, output_path):\n",
        "    # 1. Create a temporary extraction folder\n",
        "    temp_dir = \"./temp_unzip\"\n",
        "    os.makedirs(temp_dir, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        # 2. Extract all files\n",
        "        with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "            zip_ref.extractall(temp_dir)\n",
        "\n",
        "        # 3. Find seed-results.csv inside extracted files\n",
        "        target_file = None\n",
        "        for root, _, files in os.walk(temp_dir):\n",
        "            for f in files:\n",
        "                if f == output_path:\n",
        "                    target_file = os.path.join(root, f)\n",
        "                    break\n",
        "            if target_file:\n",
        "                break\n",
        "\n",
        "        if not target_file:\n",
        "            raise FileNotFoundError(\"seed-results.csv not found inside the zip archive\")\n",
        "\n",
        "        # 4. Move seed-results.csv into current working directory\n",
        "        shutil.move(target_file, output_path)\n",
        "        print(f\"✔ seed-results.csv extracted to {output_path}\")\n",
        "\n",
        "    finally:\n",
        "        # 5. Clean up: delete everything else\n",
        "        shutil.rmtree(temp_dir, ignore_errors=True)\n",
        "\n",
        "\n",
        "extract_seed_results(\"seed_output.zip\", \"seed.csv\")\n",
        "extract_seed_results(\"seed_output.zip\", \"seed-results.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "p9NoMY6ufmSE",
        "outputId": "31481ae7-ac4d-4217-9a4c-58ca547a0f67"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-08-16 17:47:52,442 | INFO | Extracting input ZIP: seed_output.zip\n",
            "2025-08-16 17:47:52,445 | INFO | Input ZIP extracted and validated.\n",
            "2025-08-16 17:47:52,446 | INFO | Reading property seed: /var/folders/g0/jndq4b_s1m96bvgtflhbx4lh0000gn/T/prop_zip_packager_2xi3gh4v/seed_output/property_seed.json\n",
            "2025-08-16 17:47:52,447 | INFO | GET https://esearch.fbcad.org/Property/View/R66725?year=2025\n",
            "2025-08-16 17:47:53,370 | INFO | Wrote HTML -> seed_output/R66725.html\n",
            "2025-08-16 17:47:53,376 | INFO | Output ZIP written -> /Users/movsiienko/Projects/elephant/notebook/output.zip\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "PosixPath('output.zip')"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# @title Step 3: Prepare\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Any, NotRequired, TypedDict, cast\n",
        "\n",
        "import json\n",
        "import logging\n",
        "import shutil\n",
        "import tempfile\n",
        "import zipfile\n",
        "from urllib.parse import urlencode\n",
        "\n",
        "import requests\n",
        "from requests import Session\n",
        "from requests.adapters import HTTPAdapter\n",
        "from urllib3.util.retry import Retry\n",
        "\n",
        "# ---------- Logging ----------\n",
        "logger = logging.getLogger(__name__)\n",
        "if not logger.handlers:\n",
        "    logging.basicConfig(level=logging.INFO, format=\"%(asctime)s | %(levelname)s | %(message)s\")\n",
        "\n",
        "\n",
        "# ---------- Types ----------\n",
        "class SourceHttpRequest(TypedDict, total=False):\n",
        "    method: str\n",
        "    url: str\n",
        "    multiValueQueryString: dict[str, Any]\n",
        "    headers: dict[str, str]\n",
        "    body: Any\n",
        "    json: Any\n",
        "\n",
        "\n",
        "class PropertySeed(TypedDict, total=False):\n",
        "    parcel_id: NotRequired[str]\n",
        "    request_identifier: NotRequired[str]\n",
        "    source_http_request: SourceHttpRequest\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class PackagerConfig:\n",
        "    input_zip: Path\n",
        "    output_zip: Path\n",
        "    timeout_sec: float = 30.0\n",
        "    retries: int = 3\n",
        "    backoff_factor: float = 1.6\n",
        "    status_forcelist: tuple[int, ...] = (429, 500, 502, 503, 504)\n",
        "\n",
        "\n",
        "# ---------- Public API ----------\n",
        "class PropertyZipPackager:\n",
        "    \"\"\"\n",
        "    Importable packager:\n",
        "      - Unpacks input ZIP with seed_output/\n",
        "      - Reads seed_output/property_seed.json\n",
        "      - Executes described HTTP request\n",
        "      - Writes HTML to seed_output/<parcel_id>.html (or <request_identifier>.html)\n",
        "      - Repackages as output ZIP\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: PackagerConfig, session: Session | None = None) -> None:\n",
        "        self.cfg = config\n",
        "        self.session = session or self._build_session()\n",
        "\n",
        "    def run(self) -> Path:\n",
        "        \"\"\"\n",
        "        Execute the pipeline. Returns the output_zip path.\n",
        "        Raises on validation/network/IO errors.\n",
        "        \"\"\"\n",
        "        self._validate_paths()\n",
        "\n",
        "        with tempfile.TemporaryDirectory(prefix=\"prop_zip_packager_\") as tmpdir:\n",
        "            workdir = Path(tmpdir)\n",
        "            self._extract_input_zip(workdir)\n",
        "\n",
        "            seed_dir = workdir / \"seed_output\"\n",
        "            seed = self._load_property_seed(seed_dir / \"property_seed.json\")\n",
        "\n",
        "            html_text = self._fetch_html_from_seed(seed)\n",
        "\n",
        "            # ---- derive filename from IDs\n",
        "            file_stem = self._resolve_identifier(seed)\n",
        "            out_html_path = seed_dir / f\"{file_stem}.html\"\n",
        "            out_html_path.write_text(html_text, encoding=\"utf-8\")\n",
        "            logger.info(\"Wrote HTML -> %s\", out_html_path.relative_to(workdir).as_posix())\n",
        "\n",
        "            self._write_output_zip(workdir)\n",
        "            logger.info(\"Output ZIP written -> %s\", self.cfg.output_zip.resolve())\n",
        "\n",
        "        return self.cfg.output_zip\n",
        "\n",
        "    # ---------- Helpers ----------\n",
        "    def _build_session(self) -> Session:\n",
        "        retry = Retry(\n",
        "            total=self.cfg.retries,\n",
        "            connect=self.cfg.retries,\n",
        "            read=self.cfg.retries,\n",
        "            status=self.cfg.retries,\n",
        "            backoff_factor=self.cfg.backoff_factor,\n",
        "            status_forcelist=self.cfg.status_forcelist,\n",
        "            allowed_methods={\"GET\", \"POST\"},\n",
        "            raise_on_status=False,\n",
        "            respect_retry_after_header=True,\n",
        "        )\n",
        "        adapter = HTTPAdapter(max_retries=retry)\n",
        "        s = requests.Session()\n",
        "        s.headers.update({\n",
        "            \"User-Agent\": (\n",
        "                \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "                \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "                \"Chrome/124.0 Safari/537.36\"\n",
        "            )\n",
        "        })\n",
        "        s.mount(\"http://\", adapter)\n",
        "        s.mount(\"https://\", adapter)\n",
        "        return s\n",
        "\n",
        "    def _validate_paths(self) -> None:\n",
        "        if not self.cfg.input_zip.exists():\n",
        "            raise FileNotFoundError(f\"Input ZIP not found: {self.cfg.input_zip}\")\n",
        "        self.cfg.output_zip.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def _extract_input_zip(self, workdir: Path) -> None:\n",
        "        logger.info(\"Extracting input ZIP: %s\", self.cfg.input_zip)\n",
        "        with zipfile.ZipFile(self.cfg.input_zip, \"r\") as zf:\n",
        "            zf.extractall(workdir)\n",
        "\n",
        "        seed_dir = workdir / \"seed_output\"\n",
        "        if not seed_dir.is_dir():\n",
        "            raise ValueError(\"Input ZIP must contain a 'seed_output/' directory.\")\n",
        "        if not (seed_dir / \"property_seed.json\").is_file():\n",
        "            raise ValueError(\"Missing 'seed_output/property_seed.json' in input ZIP.\")\n",
        "        logger.info(\"Input ZIP extracted and validated.\")\n",
        "\n",
        "    def _load_property_seed(self, path: Path) -> PropertySeed:\n",
        "        logger.info(\"Reading property seed: %s\", path)\n",
        "        try:\n",
        "            data = json.loads(path.read_text(encoding=\"utf-8\"))\n",
        "        except json.JSONDecodeError as e:\n",
        "            raise ValueError(f\"Invalid JSON in {path}: {e}\") from e\n",
        "        if not isinstance(data, dict) or \"source_http_request\" not in data:\n",
        "            raise ValueError(\"property_seed.json must include 'source_http_request'\")\n",
        "        return cast(PropertySeed, data)\n",
        "\n",
        "    def _resolve_identifier(self, seed: PropertySeed) -> str:\n",
        "        \"\"\"\n",
        "        Use parcel_id if present, else request_identifier.\n",
        "        Raise if neither is available or empty.\n",
        "        \"\"\"\n",
        "        pid = (seed.get(\"parcel_id\") or \"\").strip()\n",
        "        rid = (seed.get(\"request_identifier\") or \"\").strip()\n",
        "        ident = pid or rid\n",
        "        if not ident:\n",
        "            raise ValueError(\"property_seed.json must include 'parcel_id' or 'request_identifier' for output filename.\")\n",
        "        return ident\n",
        "\n",
        "    def _normalize_query_params(self, mvqs: dict[str, Any] | None) -> dict[str, Any]:\n",
        "        if not mvqs:\n",
        "            return {}\n",
        "        params: dict[str, Any] = {}\n",
        "        for k, v in mvqs.items():\n",
        "            if isinstance(v, list) and v:\n",
        "                params[k] = v[0]\n",
        "            else:\n",
        "                params[k] = v\n",
        "        return params\n",
        "\n",
        "    def _fetch_html_from_seed(self, seed: PropertySeed) -> str:\n",
        "        src = seed.get(\"source_http_request\", {})\n",
        "        method = (src.get(\"method\") or \"GET\").upper()\n",
        "        url = src.get(\"url\")\n",
        "        if not url:\n",
        "            raise ValueError(\"source_http_request.url is required\")\n",
        "\n",
        "        params = self._normalize_query_params(cast(dict[str, Any] | None, src.get(\"multiValueQueryString\")))\n",
        "        headers = cast(dict[str, str] | None, src.get(\"headers\")) or {}\n",
        "        body = src.get(\"body\")\n",
        "        json_body = src.get(\"json\")\n",
        "\n",
        "        kwargs: dict[str, Any] = {\"timeout\": self.cfg.timeout_sec, \"headers\": headers}\n",
        "        if method == \"GET\":\n",
        "            kwargs[\"params\"] = params\n",
        "        elif method == \"POST\":\n",
        "            kwargs[\"params\"] = params\n",
        "            if json_body is not None:\n",
        "                kwargs[\"json\"] = json_body\n",
        "            elif body is not None:\n",
        "                kwargs[\"data\"] = body\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported HTTP method: {method}\")\n",
        "\n",
        "        preview_qs = f\"?{urlencode(params)}\" if params and method == \"GET\" else \"\"\n",
        "        logger.info(\"%s %s%s\", method, url, preview_qs)\n",
        "\n",
        "        resp = self.session.request(method, url, **kwargs)\n",
        "        resp.raise_for_status()\n",
        "        return resp.text\n",
        "\n",
        "    def _write_output_zip(self, workdir: Path) -> None:\n",
        "        src_dir = Path(workdir) / \"seed_output\"\n",
        "        tmp_path = self.cfg.output_zip.with_suffix(self.cfg.output_zip.suffix + \".tmp\")\n",
        "\n",
        "        with zipfile.ZipFile(tmp_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "            for p in sorted(src_dir.rglob(\"*\")):\n",
        "                if p.is_file():\n",
        "                    arcname = p.relative_to(workdir).as_posix()\n",
        "                    zf.write(p, arcname)\n",
        "\n",
        "        shutil.move(tmp_path, self.cfg.output_zip)\n",
        "\n",
        "\n",
        "cfg = PackagerConfig(\n",
        "    input_zip=Path(\"seed_output.zip\"),\n",
        "    output_zip=Path(\"output.zip\"),\n",
        ")\n",
        "\n",
        "packager = PropertyZipPackager(cfg)\n",
        "packager.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DyG0lJvbmcej",
        "outputId": "58566f82-ee4d-4e65-d11b-760c581f477e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K\u001b[1m\u001b[34m🐘 Elephant Network CLI - Transform\u001b[39m\u001b[22m\n",
            "\n",
            "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mbackoff==2.2.1                                                                \u001b[0m\n",
            "\u001b[32m✅ Transform process finished\u001b[39m\n",
            "\u001b[1m📊 Output:\u001b[22m\n",
            "  Transformed data with HTML: \u001b[36mcounty_output.zip\u001b[39m\n",
            "\n",
            "\u001b[90mThe output ZIP contains:\u001b[39m\n",
            "\u001b[90m  - R66725/ (transformed data with HTML fact sheets)\u001b[39m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "# @title Step 4: Transform\n",
        "#!/usr/bin/env python3\n",
        "!npx -y @elephant-xyz/cli transform --group county --input-zip output.zip --input-csv seed.csv --output-zip county_output.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EDAZPaxEbCYJ",
        "outputId": "c14cb6c4-96f6-4e3f-975a-34eef2668ad7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uploaded to: https://ipfs.io/ipfs/bafybeidhik4aqjlcp3zfve7dqxqimurdzrg2qmqzwsclnvkcwnnjwudc5a/\n"
          ]
        }
      ],
      "source": [
        "# @title Step 4.5: Upload fact sheet to the IPFS\n",
        "!pip3 install python-dotenv -q\n",
        "import json\n",
        "import os\n",
        "import tempfile\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from typing import Iterable, List, Tuple\n",
        "\n",
        "import requests\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "PIN_ENDPOINT = \"https://api.pinata.cloud/pinning/pinFileToIPFS\"\n",
        "TIMEOUT = 60  # seconds\n",
        "\n",
        "\n",
        "def _first_extracted_directory(root: Path) -> Path:\n",
        "    \"\"\"Return the first subdir, or root itself if files exist directly there.\"\"\"\n",
        "    dirs = sorted([p for p in root.iterdir() if p.is_dir()])\n",
        "    return dirs[0] if dirs else root\n",
        "\n",
        "\n",
        "def _gather_non_json_files(base_dir: Path) -> Iterable[Tuple[str, Path]]:\n",
        "    \"\"\"\n",
        "    Yield (relative_path, absolute_path) for all non-JSON files under base_dir,\n",
        "    where relative_path is POSIX-style and RELATIVE TO base_dir (no leading slash).\n",
        "    \"\"\"\n",
        "    for p in base_dir.rglob(\"*\"):\n",
        "        if p.is_file() and p.suffix.lower() != \".json\":\n",
        "            rel = p.relative_to(base_dir).as_posix()\n",
        "            yield rel, p\n",
        "\n",
        "\n",
        "def pin_directory_non_json_from_zip(zip_path: Path) -> str:\n",
        "    \"\"\"\n",
        "    - Extract zip to a temp dir\n",
        "    - Pick the extracted directory (or root if files are directly inside)\n",
        "    - Upload all non-JSON files as a *directory* to Pinata, ensuring each part's filename is\n",
        "      '{dir_name}/{relative_path_within_dir}'\n",
        "    - Return a public IPFS gateway URL for the resulting CID (CIDv1)\n",
        "    \"\"\"\n",
        "    jwt = os.environ.get(\"PINATA_JWT\")\n",
        "    if not jwt:\n",
        "        raise RuntimeError(\"PINATA_JWT environment variable is required\")\n",
        "\n",
        "    headers = {\"Authorization\": f\"Bearer {jwt}\"}\n",
        "\n",
        "    with tempfile.TemporaryDirectory(prefix=\"pin_zip_\") as tmpd:\n",
        "        tmp_root = Path(tmpd)\n",
        "\n",
        "        # 1) Extract\n",
        "        with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
        "            zf.extractall(tmp_root)\n",
        "\n",
        "        # 2) Locate directory to upload\n",
        "        target_dir = _first_extracted_directory(tmp_root)\n",
        "        dir_name = target_dir.name  # used as top-level folder prefix in multipart filenames\n",
        "\n",
        "        # 3) Collect non-JSON files\n",
        "        collected = list(_gather_non_json_files(target_dir))\n",
        "        if not collected:\n",
        "            raise RuntimeError(\"No non-JSON files found to upload.\")\n",
        "\n",
        "        # 4) Build multipart payload with '{dir_name}/...' paths\n",
        "        # Keep file handles to close after the request\n",
        "        open_files: List[object] = []\n",
        "        try:\n",
        "            files_payload: List[Tuple[str, tuple]] = []\n",
        "            for rel_path, abs_path in collected:\n",
        "                # Ensure the multipart filename contains the *directory name* prefix\n",
        "                # so Pinata reconstructs the directory structure correctly.\n",
        "                multipart_name = f\"{dir_name}/{rel_path}\"\n",
        "                fobj = abs_path.open(\"rb\")\n",
        "                open_files.append(fobj)\n",
        "                files_payload.append(\n",
        "                    (\"file\", (multipart_name, fobj, \"application/octet-stream\"))\n",
        "                )\n",
        "\n",
        "            data = {\n",
        "                \"pinataOptions\": json.dumps({\"cidVersion\": 1}),\n",
        "                \"pinataMetadata\": json.dumps({\"name\": dir_name}),\n",
        "            }\n",
        "\n",
        "            # 5) Upload to Pinata\n",
        "            resp = requests.post(\n",
        "                PIN_ENDPOINT,\n",
        "                headers=headers,\n",
        "                data=data,\n",
        "                files=files_payload,\n",
        "                timeout=TIMEOUT,\n",
        "            )\n",
        "            try:\n",
        "                resp.raise_for_status()\n",
        "            except requests.HTTPError as e:\n",
        "                # Surface Pinata error response for easier debugging\n",
        "                raise RuntimeError(f\"Pinata error: {e}\\nResponse body: {resp.text}\") from e\n",
        "\n",
        "            payload = resp.json()\n",
        "            cid = payload.get(\"IpfsHash\")\n",
        "            if not cid:\n",
        "                raise RuntimeError(f\"Unexpected Pinata response (no IpfsHash): {payload}\")\n",
        "\n",
        "            return f\"https://ipfs.io/ipfs/{cid}/\"\n",
        "        finally:\n",
        "            for f in open_files:\n",
        "                try:\n",
        "                    f.close()\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "url = pin_directory_non_json_from_zip(Path(\"county_output.zip\"))\n",
        "print(\"Uploaded to:\", url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82AWqrDApExu",
        "outputId": "f40ae643-420a-48c9-d914-835da4e94fb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
            "Validation started\n"
          ]
        }
      ],
      "source": [
        "# @title Step 5: Validate\n",
        "!pip3 install python-dotenv -q\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import csv\n",
        "\n",
        "\n",
        "def has_submit_errors(path=\"submit_errors.csv\"):\n",
        "    with open(path, newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        return next(reader, None) is not None\n",
        "\n",
        "\n",
        "def run_validate():\n",
        "    try:\n",
        "        print(\"Validation started\")\n",
        "        subprocess.run(\n",
        "            [\"npx\", \"-y\", \"@elephant-xyz/cli\", \"validate\", \"county_output.zip\"],\n",
        "            stdout=subprocess.DEVNULL,\n",
        "            stderr=subprocess.PIPE,\n",
        "            check=True,\n",
        "            text=True,\n",
        "        )\n",
        "        if has_submit_errors():\n",
        "            print(\"❌ Validate failed, please check submit_errors.csv for details\", file=sys.stderr)\n",
        "            return\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Command failed (exit code {e.returncode}):\", file=sys.stderr)\n",
        "        print(e.stderr.strip(), file=sys.stderr)\n",
        "        sys.exit(e.returncode)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_validate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "IgDkOErzrfj3",
        "outputId": "69371ec5-0d65-4d8a-b6b2-6f76857d8dfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
            "✅ Hash done\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title Step 6: Hash\n",
        "\n",
        "!pip3 install python-dotenv -q\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import csv\n",
        "\n",
        "\n",
        "def has_submit_errors(path=\"submit_errors.csv\"):\n",
        "    with open(path, newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        return next(reader, None) is not None\n",
        "\n",
        "\n",
        "def get_seed_cid(path=\"seed-results.csv\"):\n",
        "    with open(path, newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        first_row = next(reader, None)\n",
        "        if first_row is None:\n",
        "            raise ValueError(\"CSV file is empty\")\n",
        "        return first_row[\"propertyCid\"]\n",
        "\n",
        "\n",
        "def run_hash():\n",
        "    try:\n",
        "        seed_group_cid = get_seed_cid()\n",
        "        subprocess.run(\n",
        "            [\n",
        "                \"npx\", \"-y\", \"@elephant-xyz/cli\",\n",
        "                \"hash\", \"county_output.zip\",\n",
        "                \"--output-zip\", \"hashed-data.zip\",\n",
        "                \"--output-csv\", \"county-results.csv\",\n",
        "                \"--property-cid\", seed_group_cid\n",
        "            ],\n",
        "            stdout=subprocess.DEVNULL,\n",
        "            stderr=subprocess.PIPE,\n",
        "            check=True,\n",
        "            text=True,\n",
        "        )\n",
        "        if has_submit_errors():\n",
        "            print(\"❌ Validate failed, please check submit_errors.csv for details\", file=sys.stderr)\n",
        "            return\n",
        "\n",
        "        print(\"✅ Hash done\\n\")\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Command failed (exit code {e.returncode}):\", file=sys.stderr)\n",
        "        print(e.stderr.strip(), file=sys.stderr)\n",
        "        sys.exit(e.returncode)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_hash()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "X7owGXJrbCYL",
        "outputId": "b4531aa0-6e59-4f29-df4d-de9c5d489d3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Upload done\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title Step 7: Upload\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def upload():\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            [\"npx\", \"-y\", \"@elephant-xyz/cli\", \"upload\", \"hashed-data.zip\", \"--output-csv\", \"county-results.csv\"],\n",
        "            stdout=subprocess.DEVNULL,\n",
        "            stderr=subprocess.PIPE,\n",
        "            check=True,\n",
        "            text=True,\n",
        "        )\n",
        "\n",
        "        print(\"✅ Upload done\\n\")\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Command failed (exit code {e.returncode}):\", file=sys.stderr)\n",
        "        print(e.stderr.strip(), file=sys.stderr)\n",
        "        sys.exit(e.returncode)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "t3sh2FAwrs-U",
        "outputId": "e3e03332-03cc-4fd5-f014-081c9c413b7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
            "✅ Submit done\n",
            "\n",
            "Transaction link: https://polygonscan.com/tx/0x4bdfc807b1aef531504cbc9caa55d8cf2553a4e303338a5dbc0fce9215eca1d9\n"
          ]
        }
      ],
      "source": [
        "# @title Step 8: Submit\n",
        "\n",
        "! pip3 install python-dotenv -q\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import csv\n",
        "\n",
        "\n",
        "def get_transaction_hash(path=\"transaction-status.csv\"):\n",
        "    with open(path, newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        first_row = next(reader, None)\n",
        "        if first_row is None:\n",
        "            raise ValueError(\"CSV file is empty\")\n",
        "        return first_row[\"transactionHash\"]\n",
        "\n",
        "\n",
        "def has_submit_errors(path=\"submit_errors.csv\"):\n",
        "    with open(path, newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        return next(reader, None) is not None\n",
        "\n",
        "\n",
        "def run_submit_to_contract():\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            [\n",
        "                \"npx\", \"-y\", \"@elephant-xyz/cli\", \"submit-to-contract\", \"county-results.csv\",\n",
        "                \"--from-address\", \"0xefAd08946612A15d5De8D4Db7fc03556b6424075\",\n",
        "                \"--api-key\", \"f7e18cf6-5d07-4e4a-ae23-f27b812614e6\",\n",
        "                \"--domain\", \"oracles-69c46050.staircaseapi.com\",\n",
        "                \"--oracle-key-id\", \"7ad26e0b-67c9-4c2f-95a2-2792c7db5ac7\",\n",
        "            ],\n",
        "            stdout=subprocess.DEVNULL,\n",
        "            stderr=subprocess.PIPE,\n",
        "            check=True,\n",
        "            text=True,\n",
        "        )\n",
        "        if has_submit_errors():\n",
        "            print(\"❌ Submit failed, please check submit_errors.csv for details\", file=sys.stderr)\n",
        "            return\n",
        "\n",
        "        transaction_hash = get_transaction_hash()\n",
        "        transaction_link = f\"https://polygonscan.com/tx/{transaction_hash}\"\n",
        "\n",
        "        print(\"✅ Submit done\\n\")\n",
        "        print(f\"Transaction link: {transaction_link}\")\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Command failed (exit code {e.returncode}):\", file=sys.stderr)\n",
        "        print(e.stderr.strip(), file=sys.stderr)\n",
        "        sys.exit(e.returncode)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_submit_to_contract()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fNupfjnBr1U2"
      },
      "outputs": [],
      "source": [
        "# @title Step 8: Download county-results.csv\n",
        "import os; from google.colab import files; (files.download('county-results.csv'), print(\"✅ File was downloaded successfully\"))[1] if os.path.exists('county-results.csv') else print(\"❌ File not found\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Mining_County.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}