{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elephant-xyz/notebook/blob/main/PhotoMedtaData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILCxMc0LIsi-"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🐘 Welcome to Step 4 of Elephant Mining\n",
        "\n",
        "Congratulations on reaching **Step 4**! By now, you’ve successfully **minted your County Data Group**. In this notebook, you'll use your **seed data** and **property images** to mint your **Photo Data Group**.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 What You’ll Do in This Step\n",
        "\n",
        "This notebook allows you to:\n",
        "\n",
        "- Upload your property images  \n",
        "- Mint a new **Photo Data Group**  \n",
        "- Automatically generate a **fact sheet** based on the image metadata  \n",
        "\n",
        "This step completes the visual layer of your dataset, setting you up for further data enrichment.\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Prerequisites\n",
        "\n",
        "Before continuing, make sure you’ve completed the following two notebooks:\n",
        "\n",
        "1. [📗 Notebook 1: Seed Minting](https://colab.research.google.com/drive/14tSNSP8Pe-mY4VwX9JhXgfyOvzmN3kC0?usp=chrome_ntp)  \n",
        "2. [📘 Notebook 2: County Data Minting](https://colab.research.google.com/drive/1ZI_eScKFh2kDIZgwXljhOgBIgrenDhRi?usp=chrome_ntp)\n",
        "\n",
        "After running both, you should have the following output files ready:\n",
        "\n",
        "- `upload-results.json`  \n",
        "- `submit.zip`\n",
        "\n",
        "Also ensure you have:\n",
        "\n",
        "- **OpenAI API Key**: Valid API key for AI processing capabilities\n",
        "- **AWS Account with Credentials**: AWS Access Key ID and Secret Access Key for cloud services\n",
        "- **Pinata Account**: JWT token for IPFS storage services\n",
        "- **Elephant Address**: Private key for blockchain integration\n",
        "\n",
        "**Required Environment Variables:**\n",
        "---\n",
        "\n",
        "## 📸 In This Notebook\n",
        "\n",
        "Once your image files are uploaded:\n",
        "\n",
        "1. The images will be minted into the **Photo Data Group**  \n",
        "2. A **fact sheet** will be generated for inspection  \n",
        "3. You can continue with **image-based metadata extraction**  \n",
        "4. This will lead to a complete and enriched data product  \n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "mz5mj3mc9A9r"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8Lh8z_QIuBx"
      },
      "source": [
        "## 📥 Step 1: Upload the `.env` File\n",
        "\n",
        "This notebook requires a `.env` file containing your API keys and credentials. Create a file with the following environment variables:\n",
        "\n",
        "| Variable Name | Purpose |\n",
        "|---|---|\n",
        "| `OPENAI_API_KEY` | Access to OpenAI API |\n",
        "| `AWS_ACCESS_KEY_ID` | AWS access key |\n",
        "| `AWS_SECRET_ACCESS_KEY` | AWS secret access key |\n",
        "| `AWS_DEFAULT_REGION` | AWS REGION |\n",
        "| `S3_BUCKET_NAME` | Your S3 bucket name |\n",
        "| `IMAGE_FOLDER_NAME` | Image directory |\n",
        "| `IMAGES_DIR` | Directory path for images |\n",
        "| `ELEPHANT_PRIVATE_KEY` | Elephant wallet private key |\n",
        "| `PINATA_JWT` | Pinata authentication token |\n",
        "\n",
        "### To upload:\n",
        "1. Click the **folder icon** 📂 in the left sidebar\n",
        "2. Click the **\"Upload\"** button\n",
        "3. Select your `.env` file\n",
        "\n",
        "### Example `.env` file:\n",
        "```env\n",
        "OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
        "AWS_ACCESS_KEY_ID=XXXXXX\n",
        "AWS_SECRET_ACCESS_KEY=XXXXXX\n",
        "S3_BUCKET_NAME=your-s3-bucket-name-here\n",
        "IMAGES_DIR=images\n",
        "IMAGE_FOLDER_NAME=images\n",
        "ELEPHANT_PRIVATE_KEY=xxxxx\n",
        "PINATA_JWT=xxxxx\n",
        "```\n",
        "\n",
        "> ⚠️ **Security Note:** Never commit your `.env` file to version control or share it publicly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4A8fm24ILQ8s"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q36E40RNVE3"
      },
      "source": [
        "## Step 2: Upload `upload_results.csv`\n",
        "\n",
        "Upload the `upload_results.csv` file to the `/content/` directory.\n",
        "\n",
        "> 📌 **Important**: This file was generated by running **Step 2** of the [Seed Data Notebook](https://colab.research.google.com/drive/14tSNSP8Pe-mY4VwX9JhXgfyOvzmN3kC0?usp=sharing#scrollTo=OFKp4E49651Z)\n",
        "\n",
        "The file should now be downloaded and ready to upload to `/content/upload_results.csv`\n",
        "\n",
        "## Step 3: Upload `submit.zip`\n",
        "\n",
        "Upload the `submit.zip` file to the `/content/` directory.\n",
        "\n",
        "> 📌 **Important**: This file was generated by running **Step 3** of the [County Data Notebook](https://colab.research.google.com/drive/1ZI_eScKFh2kDIZgwXljhOgBIgrenDhRi#scrollTo=HA0ppLFpUm1j)\n",
        "\n",
        "The file should now be downloaded and ready to upload to `/content/submit.zip`\n",
        "\n",
        "## Step 4: Verify Data Exists\n",
        "\n",
        "Once both files are uploaded to `/content/`, you can proceed with the main workflow that depends on these generated datasets.\n",
        "\n",
        "**Expected file locations:**\n",
        "- `/content/upload-results.csv`\n",
        "- `/content/submit.zip`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la /content/upload-results.csv\n",
        "!ls -la /content/submit.zip"
      ],
      "metadata": {
        "id": "DdykRvx-3jW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "218e32d0-222a-4c48-ab91-7d3a59986559"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 449 Jul 26 00:32 /content/upload-results.csv\n",
            "-rw-r--r-- 1 root root 30282 Jul 26 00:32 /content/submit.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F000A7O3PtrJ"
      },
      "source": [
        "##Step 5: Install Package & Setup Folders\n",
        "This step:\n",
        "\n",
        "Installs the photo-meta-data-ai package from GitHub\n",
        "Creates all necessary folders for the project\n",
        "Saves installation details to a log file for troubleshooting\n",
        "\n",
        "Takes 1-2 minutes to complete. Once finished, you'll have the AI package installed and folder structure ready for processing photos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "yiY6rgFYPvU6"
      },
      "outputs": [],
      "source": [
        "# 1. Install the package\n",
        "!pip install --force-reinstall --no-cache-dir git+https://github.com/elephant-xyz/photo-meta-data-ai.git > /content/install_log.txt 2>&1\n",
        "\n",
        "# 2. Set up folders\n",
        "!colab-folder-setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojt2s4z6NxC1"
      },
      "source": [
        "##Step 6: Upload Images to Property Subfolders\n",
        "Upload your property images into the pre-created subfolders:\n",
        "\n",
        "Each property already has a subfolder named with its Parcel ID under the images folder\n",
        "Simply drag and drop your images into the correct property subfolder\n",
        "All images for a specific property should go in that property's designated folder\n",
        "\n",
        "The AI will process each property's images and generate metadata organized by Parcel ID.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "y04HMnMuiAT5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8 Uploading Photos"
      ],
      "metadata": {
        "id": "fX_uvmsi1wro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!process-photo-data\n",
        "!npx -y @elephant-xyz/cli@latest validate-and-upload photo_data_group --output-csv photos.csv"
      ],
      "metadata": {
        "id": "FL2oPh-S3eya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bc6e5e8-d819-4d04-afde-3a39285386bd"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - Processed bafkreigzz5foh5ts76vvhxphzulptpnjwznog6lcnxw5wsvfqa7zlxeioa: 74 images, root.json created\n",
            "\n",
            "Processing complete:\n",
            "  - Processed 1 directories with images\n",
            "  - Generated 74 image metadata files\n",
            "  - Each directory has its own root.json\n",
            "  - Supported formats: .jpeg, .jpg, .png, .webp\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\u001b[1m\u001b[34m🐘 Elephant Network CLI - Validate and Upload\u001b[39m\u001b[22m\n",
            "\n",
            "\u001b7\u001b[?25l\u001b[?7l\u001b[1GInitializing    |\u001b[36m████████████████████████████████████████\u001b[39m| 100% | 0/0 | Errors: 0 | Skipped: 0 | 0s | ETA: 0s\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/1 | Errors: 0 | Skipped: 0 | 0s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/1 | Errors: 0 | Skipped: 0 | 1s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/1 | Errors: 0 | Skipped: 0 | 2s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/1 | Errors: 0 | Skipped: 0 | 3s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/1 | Errors: 0 | Skipped: 0 | 4s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/1 | Errors: 0 | Skipped: 0 | 5s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/1 | Errors: 0 | Skipped: 0 | 6s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/1 | Errors: 0 | Skipped: 0 | 7s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/1 | Errors: 0 | Skipped: 0 | 8s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/1 | Errors: 0 | Skipped: 0 | 9s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/1 | Errors: 0 | Skipped: 0 | 10s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/1 | Errors: 0 | Skipped: 0 | 11s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/1 | Errors: 0 | Skipped: 0 | 12s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/1 | Errors: 0 | Skipped: 0 | 13s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/1 | Errors: 0 | Skipped: 0 | 14s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/1 | Errors: 0 | Skipped: 0 | 15s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/1 | Errors: 0 | Skipped: 0 | 16s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m████████████████████████████████████████\u001b[39m| 100% | 1/1 | Errors: 0 | Skipped: 0 | 16s | ETA: 0s\u001b[0K\u001b[1GInstalling/Updating Fact Sheet Tool |\u001b[36m████████████████████████████████████████\u001b[39m| 100% | 1/1 | Errors: 0 | Skipped: 0 | 18s | ETA: 0s\u001b[0K\u001b[1GGenerating HTML Files |\u001b[36m████████████████████████████████████████\u001b[39m| 100% | 1/1 | Errors: 0 | Skipped: 0 | 18s | ETA: 0s\u001b[0K\u001b[?25h\u001b[?7h\u001b8\n",
            "\u001b[32m\u001b[39m\n",
            "\u001b[32m✅ Validation and upload process finished\u001b[39m\n",
            "\u001b[32m\u001b[39m\n",
            "\u001b[1m📊 Final Report:\u001b[22m\n",
            "  Total files scanned:    1\n",
            "  Files skipped: 0\n",
            "  Processing/upload errors: 0\n",
            "  Successfully processed (validated & uploaded):  1\n",
            "  Total files handled:    1\n",
            "  Duration:               0s\n",
            "\n",
            "  Error report:   ./submit_errors.csv\n",
            "  Warning report: ./submit_warnings.csv\n",
            "  Upload results: photos.csv\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 9: Submitting Your Data to the Blockchain\n",
        "\n",
        "### Submitting Your Data\n",
        "\n",
        "After running the upload command in the notebook:\n",
        "\n",
        "1. **Download your results file**\n",
        "   - The notebook will generate `photos.csv`\n",
        "   - This file contains your data hashes and IPFS CIDs\n",
        "   - Download it to your computer\n",
        "\n",
        "2. **Visit the Oracle Submission Portal**\n",
        "   - Go to https://oracle.elephant.xyz/\n",
        "   - Connect your MetaMask wallet when prompted\n",
        "   - Upload your `submit-results.csv` file\n",
        "\n",
        "3. **Submit transactions**\n",
        "   - The portal will read your CSV and prepare transactions\n",
        "   - Click \"Submit to Contract\" to begin\n",
        "   - MetaMask will pop up for each data entry\n",
        "   - Confirm each transaction (small gas fee applies)\n",
        "   - Wait for confirmations between submissions\n",
        "\n",
        "Once complete, your data is permanently recorded on the blockchain. You'll receive vMahout tokens as rewards after consensus is reached (when 3 different oracles submit matching data hashes)."
      ],
      "metadata": {
        "id": "cAxcVrYl7vA9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJo3i5enWo0J"
      },
      "source": [
        "## Step 10: Setup and Run AWS Rekognition\n",
        "\n",
        "The system automatically sets up and runs Amazon Rekognition to analyze your property images:\n",
        "\n",
        "- Connects to AWS Rekognition service for AI-powered image analysis\n",
        "- Processes all images in your property folders automatically\n",
        "- Extracts detailed information like room types, architectural features, and property characteristics\n",
        "\n",
        "No action needed from you - the system handles everything automatically and will notify you when processing is complete.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "G2eZfzTpOGV0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f89b94f-f20b-4c08-a399-6aef10df0afe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "📊 COMPREHENSIVE CATEGORIZATION SUMMARY\n",
            "================================================================================\n",
            "\n",
            "🏠 TOTAL PROPERTIES PROCESSED: 1\n",
            "🖼️  TOTAL IMAGES: 74\n",
            "✅ TOTAL CATEGORIZED: 74\n",
            "📈 SUCCESS RATE: 100.0%\n",
            "\n",
            "📁 OVERALL CATEGORY BREAKDOWN:\n",
            "   exterior: 30 images\n",
            "   living_room: 14 images\n",
            "   kitchen: 12 images\n",
            "   other: 6 images\n",
            "   bedroom: 6 images\n",
            "   closet: 2 images\n",
            "   garage: 2 images\n",
            "   laundry: 1 images\n",
            "   pool: 1 images\n",
            "\n",
            "🏠 PROPERTY-BY-PROPERTY BREAKDOWN:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "📍 Property: 52434205310037080\n",
            "   Address: Property 52434205310037080\n",
            "   Total Images: 74\n",
            "   Categorized: 74\n",
            "   Success Rate: 100.0%\n",
            "   Categories:\n",
            "     • exterior: 30 images\n",
            "     • living_room: 14 images\n",
            "     • kitchen: 12 images\n",
            "     • other: 6 images\n",
            "     • bedroom: 6 images\n",
            "     • closet: 2 images\n",
            "     • garage: 2 images\n",
            "     • laundry: 1 images\n",
            "     • pool: 1 images\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "!bucket-manager\n",
        "!unzip-county-data\n",
        "!upload-to-s3\n",
        "!photo-categorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo7Jjafq6N1i"
      },
      "source": [
        "## Step 11: Running AI to Extract Data from Images\n",
        "\n",
        "The AI system now analyzes your property images to extract valuable metadata:\n",
        "\n",
        "1. **Image Analysis**: AI examines each photo to identify rooms, features, and property details\n",
        "2. **Data Extraction**: System pulls out structured information like room types, square footage estimates, architectural elements, and condition assessments\n",
        "\n",
        "The process runs automatically across all your uploaded property images, generating comprehensive metadata reports for each parcel.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "67Sqqv2xcurU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3c58403-6bff-453b-da50-ca39eb76d586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "PROPERTY SUMMARY: 52434205310037080\n",
            "============================================================\n",
            "\n",
            "📋 LAYOUTS (13 total)\n",
            "----------------------------------------\n",
            "Space Types:\n",
            "  • Laundry Room\n",
            "  • Bedroom\n",
            "  • Home Office\n",
            "  • Dining Room\n",
            "  • Pantry\n",
            "  • Attached Garage\n",
            "  • Living Room\n",
            "  • Full Bathroom\n",
            "  • Closet\n",
            "  • Kitchen\n",
            "  • Laundry Room: \n",
            "  • Bedroom: \n",
            "  • Home Office: \n",
            "  • Bedroom: \n",
            "  • Dining Room: \n",
            "  • Pantry: \n",
            "  • Attached Garage: \n",
            "  • Living Room: \n",
            "  • Full Bathroom: \n",
            "  • Closet: \n",
            "  • Full Bathroom: \n",
            "  • Kitchen: \n",
            "  • Full Bathroom: \n",
            "\n",
            "🏠 STRUCTURE\n",
            "----------------------------------------\n",
            "  No structure data found\n",
            "\n",
            "🌳 LOT\n",
            "----------------------------------------\n",
            "  No lot data found\n",
            "\n",
            "⚡ UTILITIES\n",
            "----------------------------------------\n",
            "  No utility data found\n",
            "\n",
            "🔌 APPLIANCES (5 total)\n",
            "----------------------------------------\n",
            "Types: Oven, Microwave, Washing Machine, Refrigerator\n",
            "  • Oven\n",
            "  • Microwave\n",
            "  • Washing Machine\n",
            "  • Refrigerator\n",
            "\n",
            "============================================================\n",
            "\n",
            "================================================================================\n",
            "🎉 COMPLETED: Summarized 1 properties\n",
            "================================================================================\n",
            "  • 52434205310037080: 13 layouts, 5 appliances\n"
          ]
        }
      ],
      "source": [
        "!ai-analyzer --local-folders --parallel-categories --all-properties\n",
        "!property-summarizer --all-properties"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WEPamAD7h4F"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKHWrLc47vUv"
      },
      "source": [
        "## Step 12: Data Validation and Submission\n",
        "\n",
        "The system validates extracted data and prepares it for final submission:\n",
        "\n",
        "1. **Data Validation**: Reviews and verifies all extracted metadata for accuracy\n",
        "2. **Submission Preparation**: Validated data is formatted and organized for CLI submission\n",
        "3. **CLI Submission**: System automatically submits the processed data through the command line interface\n",
        "4. **Fact Sheet Generation**: Creates comprehensive property fact sheets with all extracted information, images, and metadata\n",
        "\n",
        "Final deliverables include validated property reports and detailed fact sheets ready for use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "Z33zRmVR7zVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9291f5f2-fd18-4e7d-9630-96988b4a3a2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K\u001b[1m\u001b[34m🐘 Elephant Network CLI - Validate and Upload\u001b[39m\u001b[22m\n",
            "\n",
            "\u001b7\u001b[?25l\u001b[?7l\u001b[1GInitializing    |\u001b[36m████████████████████████████████████████\u001b[39m| 100% | 0/0 | Errors: 0 | Skipped: 0 | 0s | ETA: 0s\u001b[0K\u001b7\u001b[?25l\u001b[?7l\u001b[1GFetching Schemas |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/2 | Errors: 0 | Skipped: 0 | 0s | ETA: 0s\u001b[0K\u001b[1GPre-fetching Schemas |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/1 | Errors: 0 | Skipped: 0 | 0s | ETA: NFs\u001b[0K\u001b[1GFetching Schemas |\u001b[36m████████████████████████████████████████\u001b[39m| 100% | 2/2 | Errors: 0 | Skipped: 0 | 0s | ETA: 0s\u001b[0K\u001b[?25h\u001b[?7h\u001b8\n",
            "\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/2 | Errors: 0 | Skipped: 0 | 0s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/2 | Errors: 0 | Skipped: 0 | 1s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/2 | Errors: 0 | Skipped: 0 | 2s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/2 | Errors: 0 | Skipped: 0 | 3s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/2 | Errors: 0 | Skipped: 0 | 4s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/2 | Errors: 0 | Skipped: 0 | 5s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/2 | Errors: 0 | Skipped: 0 | 6s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/2 | Errors: 0 | Skipped: 0 | 7s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/2 | Errors: 0 | Skipped: 0 | 8s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/2 | Errors: 0 | Skipped: 0 | 9s | ETA: NFs\u001b[0K\u001b[1GProcessing Files |\u001b[36m████████████████████░░░░░░░░░░░░░░░░░░░░\u001b[39m| 50% | 1/2 | Errors: 0 | Skipped: 0 | 9s | ETA: 9s\u001b[0K\u001b[1GProcessing Files |\u001b[36m████████████████████░░░░░░░░░░░░░░░░░░░░\u001b[39m| 50% | 1/2 | Errors: 0 | Skipped: 0 | 10s | ETA: 9s\u001b[0K\u001b[1GProcessing Files |\u001b[36m████████████████████████████████████████\u001b[39m| 100% | 2/2 | Errors: 0 | Skipped: 0 | 10s | ETA: 0s\u001b[0K\u001b[1GInstalling/Updating Fact Sheet Tool |\u001b[36m████████████████████████████████████████\u001b[39m| 100% | 1/1 | Errors: 0 | Skipped: 0 | 11s | ETA: 0s\u001b[0K\u001b[1GGenerating HTML Files |\u001b[36m████████████████████████████████████████\u001b[39m| 100% | 1/1 | Errors: 0 | Skipped: 0 | 11s | ETA: 0s\u001b[0K\u001b[1GUploading HTML Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/1 | Errors: 0 | Skipped: 0 | 12s | ETA: NFs\u001b[0K\u001b[1GUploading HTML Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/1 | Errors: 0 | Skipped: 0 | 13s | ETA: NFs\u001b[0K\u001b[1GUploading HTML Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/1 | Errors: 0 | Skipped: 0 | 14s | ETA: NFs\u001b[0K\u001b[1GUploading HTML Files |\u001b[36m░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\u001b[39m| 0% | 0/1 | Errors: 0 | Skipped: 0 | 15s | ETA: NFs\u001b[0K\u001b[1GUploading HTML Files |\u001b[36m████████████████████████████████████████\u001b[39m| 100% | 1/1 | Errors: 0 | Skipped: 0 | 16s | ETA: 0s\u001b[0K\u001b[?25h\u001b[?7h\u001b8\n",
            "\u001b[32m\u001b[39m\n",
            "\u001b[32m✅ Validation and upload process finished\u001b[39m\n",
            "\u001b[32m\u001b[39m\n",
            "\u001b[1m📊 Final Report:\u001b[22m\n",
            "  Total files scanned:    1\n",
            "  Files skipped: 0\n",
            "  Processing/upload errors: 0\n",
            "  Successfully processed (validated & uploaded):  1\n",
            "  Total files handled:    1\n",
            "  Duration:               4s\n",
            "\n",
            "  Error report:   ./submit_errors.csv\n",
            "  Warning report: ./submit_warnings.csv\n",
            "  Upload results: submit-results.csv\n",
            "\u001b[1m\u001b[22m\n",
            "\u001b[1m🌐 Property Fact Sheet Links:\u001b[22m\n",
            "\u001b[90m  (Note: It may take a few minutes for pages to propagate through IPFS gateways)\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "  1. Directory: bafkreigzz5foh5ts76vvhxphzulptpnjwznog6lcnxw5wsvfqa7zlxeioa\n",
            "     \u001b[36mhttp://dweb.link/ipfs/bafybeihq5maoqch3pv5iiqwcalddpbmfwx6aohwjeki56p6xo2gx7c7wku\u001b[39m\n",
            "\n",
            "\u001b[1m\u001b[22m\n",
            "\u001b[1m📄 All HTML links have been saved to: \u001b[32msubmit-results.csv\u001b[39m\u001b[22m\n",
            "\u001b[90m  Please check this file for the complete list of property fact sheet URLs.\u001b[39m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "!fix-schema-validation\n",
        "!copy-all-data-for-submission\n",
        "!copy-all-files-from-zip\n",
        "!npx @elephant-xyz/cli@1.16.2 validate-and-upload submit-photo --output-csv submit-results.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 13: Submitting Your Data to the Blockchain\n",
        "\n",
        "### Submitting Your Data\n",
        "\n",
        "After running the upload command in the notebook:\n",
        "\n",
        "1. **Download your results file**\n",
        "   - The notebook will generate `submit-results.csv`\n",
        "   - This file contains your data hashes and IPFS CIDs\n",
        "   - Download it to your computer\n",
        "\n",
        "2. **Visit the Oracle Submission Portal**\n",
        "   - Go to https://oracle.elephant.xyz/\n",
        "   - Connect your MetaMask wallet when prompted\n",
        "   - Upload your `submit-results.csv` file\n",
        "\n",
        "3. **Submit transactions**\n",
        "   - The portal will read your CSV and prepare transactions\n",
        "   - Click \"Submit to Contract\" to begin\n",
        "   - MetaMask will pop up for each data entry\n",
        "   - Confirm each transaction (small gas fee applies)\n",
        "   - Wait for confirmations between submissions\n",
        "\n",
        "Once complete, your data is permanently recorded on the blockchain. You'll receive vMahout tokens as rewards after consensus is reached (when 3 different oracles submit matching data hashes)."
      ],
      "metadata": {
        "id": "-DsIg-MR3Rrj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 14: Package and Download Results\n",
        "\n",
        "This step creates downloadable files with all your processed data. The system will:\n",
        "\n",
        "1. **Create Download Package**: Automatically zip the submit-photos folder containing all fact sheets and processed images\n",
        "\n",
        "2. **Download Results**: Two files will be made available for download\n",
        "\n",
        "**Files to Download:**\n",
        "- `submit-results.csv` - Structured data with all extracted property metadata\n",
        "- `submit-photo.zip` - Complete package containing fact sheets and processed images\n",
        "\n",
        "Your processed property data is now saved locally for use."
      ],
      "metadata": {
        "id": "KEeTcfuy5dEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r submit-photo.zip submit-photo/ > /dev/null 2>&1\n",
        "\n"
      ],
      "metadata": {
        "id": "Z8Jw-Bxu6Oa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 15: Cleanup\n",
        "\n",
        "Final and optional step to save your results and clean up the workspace:\n",
        "\n",
        "3. **Cleanup Workspace**: After downloading, the system removes all temporary files and folders including:\n",
        "  - `images` folder (uploaded property photos)\n",
        "  - `output` folder (processing files)\n",
        "  - `county-data` folder (temporary data)\n",
        "  - `submit-photos` folder (final results)\n",
        "  - `logs` folder (processing logs)\n",
        "\n",
        "**Important**: Make sure to download your results before the cleanup step, as all files will be permanently deleted from the workspace."
      ],
      "metadata": {
        "id": "t4sJUpBJ8uru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf images/ output/ county-data/ submit-photo/ logs/ photo_data_group/ > /dev/null 2>&1\n",
        "!find . -maxdepth 1 -type f \\( -name \"*.csv\" -o -name \"*.zip\" -o -name \"*.log\" -o -name \"*.txt\" -o -name \".env\" \\) -exec rm -f {} \\;\n",
        "\n",
        "!rm -rf /root/.local/bin/fact-sheet\n",
        "!rm -rf fact-sheet-template/\n",
        "!rm -rf /root/.elephant-fact-sheet"
      ],
      "metadata": {
        "id": "HTwgC_Wd8_pA"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "set -e\n",
        "\n",
        "# Colors (won’t display in Colab but kept for compatibility)\n",
        "GREEN='\\033[0;32m'\n",
        "BLUE='\\033[0;34m'\n",
        "RED='\\033[0;31m'\n",
        "NC='\\033[0m'\n",
        "\n",
        "INSTALL_DIR=\"${HOME}/.elephant-fact-sheet\"\n",
        "BIN_DIR=\"${HOME}/.local/bin\"\n",
        "\n",
        "echo -e \"${BLUE}🐘 Elephant Fact Sheet Template Installer${NC}\"\n",
        "\n",
        "# Check Node.js\n",
        "if ! command -v node &> /dev/null; then\n",
        "    echo -e \"${RED}❌ Node.js is not installed${NC}\"\n",
        "    exit 1\n",
        "fi\n",
        "\n",
        "NODE_VERSION=$(node -v | cut -d'v' -f2 | cut -d'.' -f1)\n",
        "if [ \"$NODE_VERSION\" -lt 18 ]; then\n",
        "    echo -e \"${RED}❌ Node.js 18+ required${NC}\"\n",
        "    exit 1\n",
        "fi\n",
        "\n",
        "echo -e \"${GREEN}✓ Node.js $(node -v) and npm $(npm -v) detected${NC}\"\n",
        "\n",
        "# Cleanup\n",
        "rm -rf \"$INSTALL_DIR\"\n",
        "mkdir -p \"$BIN_DIR\"\n",
        "\n",
        "# Clone and build\n",
        "echo $INSTALL_DIR\n",
        "git clone https://github.com/elephant-xyz/fact-sheet-template.git \"$INSTALL_DIR\"\n",
        "cd \"$INSTALL_DIR\"\n",
        "npm install\n",
        "npm run build\n",
        "npm link\n",
        "\n",
        "# Symlink\n",
        "ln -sf \"$INSTALL_DIR/bin/fact-sheet.js\" /root/.local/bin/fact-sheet\n",
        "chmod +x \"$INSTALL_DIR/bin/fact-sheet.js\"\n",
        "\n",
        "echo \"\"\n",
        "echo -e \"${GREEN}✅ Installed successfully in $INSTALL_DIR${NC}\"\n",
        "echo \"To run it:\"\n",
        "echo \"    node $INSTALL_DIR/bin/fact-sheet.js --help\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmLLEpfKU4zS",
        "outputId": "68f419d5-1d3c-45da-d50c-db0eb298998e"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0;34m🐘 Elephant Fact Sheet Template Installer\u001b[0m\n",
            "\u001b[0;32m✓ Node.js v20.19.0 and npm 10.8.2 detected\u001b[0m\n",
            "/root/.elephant-fact-sheet\n",
            "\n",
            "> @elephant/fact-sheet@1.0.0 postinstall\n",
            "> npm run build\n",
            "\n",
            "\n",
            "> @elephant/fact-sheet@1.0.0 build\n",
            "> tsc\n",
            "\n",
            "\n",
            "> @elephant/fact-sheet@1.0.0 prepare\n",
            "> npm run build\n",
            "\n",
            "\n",
            "> @elephant/fact-sheet@1.0.0 build\n",
            "> tsc\n",
            "\n",
            "\n",
            "added 242 packages, and audited 243 packages in 12s\n",
            "\n",
            "63 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 0 vulnerabilities\n",
            "\n",
            "> @elephant/fact-sheet@1.0.0 build\n",
            "> tsc\n",
            "\n",
            "\n",
            "up to date, audited 3 packages in 10s\n",
            "\n",
            "found 0 vulnerabilities\n",
            "\n",
            "\u001b[0;32m✅ Installed successfully in /root/.elephant-fact-sheet\u001b[0m\n",
            "To run it:\n",
            "    node /root/.elephant-fact-sheet/bin/fact-sheet.js --help\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into '/root/.elephant-fact-sheet'...\n",
            "npm warn deprecated inflight@1.0.6: This module is not supported, and leaks memory. Do not use it. Check out lru-cache if you want a good and tested way to coalesce async requests by a key value, which is much more comprehensive and powerful.\n",
            "npm warn deprecated @humanwhocodes/config-array@0.13.0: Use @eslint/config-array instead\n",
            "npm warn deprecated rimraf@3.0.2: Rimraf versions prior to v4 are no longer supported\n",
            "npm warn deprecated @humanwhocodes/object-schema@2.0.3: Use @eslint/object-schema instead\n",
            "npm warn deprecated glob@7.2.3: Glob versions prior to v9 are no longer supported\n",
            "npm warn deprecated eslint@8.57.1: This version is no longer supported. Please see https://eslint.org/version-support for other options.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"$INSTALL_DIR\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZawTinvb1Y3",
        "outputId": "6c7b5269-a23f-4a79-e3f0-7c3418c71550"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "# Elephant Fact Sheet Template Installer\n",
        "# This script clones the repository, builds it, and sets up the command globally\n",
        "\n",
        "set -e  # Exit on error\n",
        "\n",
        "# Colors for output\n",
        "GREEN='\\033[0;32m'\n",
        "BLUE='\\033[0;34m'\n",
        "RED='\\033[0;31m'\n",
        "NC='\\033[0m' # No Color\n",
        "\n",
        "# Default installation directory\n",
        "INSTALL_DIR=\"${HOME}/.elephant-fact-sheet\"\n",
        "BIN_DIR=\"${HOME}/.local/bin\"\n",
        "\n",
        "echo -e \"${BLUE}🐘 Elephant Fact Sheet Template Installer${NC}\"\n",
        "echo \"\"\n",
        "\n",
        "# Check if Node.js is installed\n",
        "if ! command -v node &> /dev/null; then\n",
        "    echo -e \"${RED}❌ Node.js is not installed. Please install Node.js 18+ first.${NC}\"\n",
        "    exit 1\n",
        "fi\n",
        "\n",
        "# Check Node.js version\n",
        "NODE_VERSION=$(node -v | cut -d'v' -f2 | cut -d'.' -f1)\n",
        "if [ \"$NODE_VERSION\" -lt 18 ]; then\n",
        "    echo -e \"${RED}❌ Node.js 18+ is required. Current version: $(node -v)${NC}\"\n",
        "    exit 1\n",
        "fi\n",
        "\n",
        "# Check if npm is installed\n",
        "if ! command -v npm &> /dev/null; then\n",
        "    echo -e \"${RED}❌ npm is not installed. Please install npm first.${NC}\"\n",
        "    exit 1\n",
        "fi\n",
        "\n",
        "echo -e \"${GREEN}✓ Node.js $(node -v) and npm $(npm -v) detected${NC}\"\n",
        "echo \"\"\n",
        "\n",
        "# Remove existing installation if present\n",
        "if [ -d \"$INSTALL_DIR\" ]; then\n",
        "    echo \"Removing existing installation...\"\n",
        "    rm -rf \"$INSTALL_DIR\"\n",
        "fi\n",
        "\n",
        "# Clone the repository\n",
        "echo \"Cloning repository...\"\n",
        "git clone https://github.com/elephant-xyz/fact-sheet-template.git \"$INSTALL_DIR\"\n",
        "\n",
        "# Navigate to installation directory\n",
        "cd \"$INSTALL_DIR\"\n",
        "\n",
        "# Install dependencies\n",
        "echo \"\"\n",
        "echo \"Installing dependencies...\"\n",
        "npm install\n",
        "\n",
        "# Build the project\n",
        "echo \"\"\n",
        "echo \"Building project...\"\n",
        "npm run build\n",
        "\n",
        "# Create bin directory if it doesn't exist\n",
        "mkdir -p \"$BIN_DIR\"\n",
        "\n",
        "STATIC_TARGET_DIR=\"$BIN_DIR/assets/static\"\n",
        "mkdir -p \"$STATIC_TARGET_DIR\"\n",
        "cp -r \"$INSTALL_DIR/template/assets/static/\"* \"$STATIC_TARGET_DIR\"\n",
        "\n",
        "# Create symlink for global command\n",
        "echo \"\"\n",
        "echo \"Setting up global command...\"\n",
        "ln -sf \"$INSTALL_DIR/bin/fact-sheet.js\" \"$BIN_DIR/fact-sheet\"\n",
        "\n",
        "# Make the script executable\n",
        "chmod +x \"$INSTALL_DIR/bin/fact-sheet.js\"\n",
        "\n",
        "# Check if ~/.local/bin is in PATH\n",
        "if [[ \":$PATH:\" != *\":$BIN_DIR:\"* ]]; then\n",
        "    echo \"\"\n",
        "    echo -e \"${BLUE}ℹ️  Add the following line to your shell configuration file (.bashrc, .zshrc, etc.):${NC}\"\n",
        "    echo \"\"\n",
        "    echo \"    export PATH=\\\"\\$HOME/.local/bin:\\$PATH\\\"\"\n",
        "    echo \"\"\n",
        "    echo \"Then reload your shell configuration:\"\n",
        "    echo \"    source ~/.bashrc  # or source ~/.zshrc\"\n",
        "    echo \"\"\n",
        "else\n",
        "    echo -e \"${GREEN}✓ $BIN_DIR is already in your PATH${NC}\"\n",
        "fi\n",
        "\n",
        "echo \"\"\n",
        "echo -e \"${GREEN}✅ Installation complete!${NC}\"\n",
        "echo \"\"\n",
        "echo \"You can now use the fact-sheet command:\"\n",
        "echo \"    fact-sheet generate --input ./data --output ./websites\"\n",
        "echo \"\"\n",
        "echo \"For help:\"\n",
        "echo \"    fact-sheet --help\"\n",
        "echo \"\"\n",
        "echo \"To uninstall, run:\"\n",
        "echo \"    rm -rf $INSTALL_DIR\"\n",
        "echo \"    rm $BIN_DIR/fact-sheet\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wOLsnAdf9Vc",
        "outputId": "25b8dd99-f29c-4ece-cf34-bb1d153ff3b0"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0;34m🐘 Elephant Fact Sheet Template Installer\u001b[0m\n",
            "\n",
            "\u001b[0;32m✓ Node.js v20.19.0 and npm 10.8.2 detected\u001b[0m\n",
            "\n",
            "Removing existing installation...\n",
            "Cloning repository...\n",
            "\n",
            "Installing dependencies...\n",
            "\n",
            "> @elephant/fact-sheet@1.0.0 postinstall\n",
            "> npm run build\n",
            "\n",
            "\n",
            "> @elephant/fact-sheet@1.0.0 build\n",
            "> tsc\n",
            "\n",
            "\n",
            "> @elephant/fact-sheet@1.0.0 prepare\n",
            "> npm run build\n",
            "\n",
            "\n",
            "> @elephant/fact-sheet@1.0.0 build\n",
            "> tsc\n",
            "\n",
            "\n",
            "added 242 packages, and audited 243 packages in 12s\n",
            "\n",
            "63 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 0 vulnerabilities\n",
            "\n",
            "Building project...\n",
            "\n",
            "> @elephant/fact-sheet@1.0.0 build\n",
            "> tsc\n",
            "\n",
            "\n",
            "Setting up global command...\n",
            "\n",
            "\u001b[0;34mℹ️  Add the following line to your shell configuration file (.bashrc, .zshrc, etc.):\u001b[0m\n",
            "\n",
            "    export PATH=\"$HOME/.local/bin:$PATH\"\n",
            "\n",
            "Then reload your shell configuration:\n",
            "    source ~/.bashrc  # or source ~/.zshrc\n",
            "\n",
            "\n",
            "\u001b[0;32m✅ Installation complete!\u001b[0m\n",
            "\n",
            "You can now use the fact-sheet command:\n",
            "    fact-sheet generate --input ./data --output ./websites\n",
            "\n",
            "For help:\n",
            "    fact-sheet --help\n",
            "\n",
            "To uninstall, run:\n",
            "    rm -rf /root/.elephant-fact-sheet\n",
            "    rm /root/.local/bin/fact-sheet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into '/root/.elephant-fact-sheet'...\n",
            "npm warn deprecated inflight@1.0.6: This module is not supported, and leaks memory. Do not use it. Check out lru-cache if you want a good and tested way to coalesce async requests by a key value, which is much more comprehensive and powerful.\n",
            "npm warn deprecated @humanwhocodes/config-array@0.13.0: Use @eslint/config-array instead\n",
            "npm warn deprecated rimraf@3.0.2: Rimraf versions prior to v4 are no longer supported\n",
            "npm warn deprecated @humanwhocodes/object-schema@2.0.3: Use @eslint/object-schema instead\n",
            "npm warn deprecated glob@7.2.3: Glob versions prior to v9 are no longer supported\n",
            "npm warn deprecated eslint@8.57.1: This version is no longer supported. Please see https://eslint.org/version-support for other options.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}