{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXexpNe02TH0OKH4TxNCHp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elephant-xyz/photo-meta-data-notebook/blob/main/PhotoMedtaData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ILCxMc0LIsi-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔄 Load Existing `.env` File\n",
        "\n",
        "This step will load environment variables from an existing `.env` file already uploaded to the Colab environment.\n",
        "\n",
        "The following variables are expected:\n",
        "\n",
        "| Variable Name           | Purpose                     |\n",
        "|-------------------------|-----------------------------|\n",
        "| `OPENAI_API_KEY`        | Access to OpenAI API        |\n",
        "| `AWS_ACCESS_KEY_ID`     | AWS access key              |\n",
        "| `AWS_SECRET_ACCESS_KEY` | AWS secret access key       |\n",
        "| `S3_BUCKET_NAME`        | S3 BUCKET NAME              |\n",
        "| `IMAGES_DIR`            | The local folder for images\n",
        "\n",
        "\n",
        "\n",
        "> ✅ Make sure `.env` is present in the file list on the left sidebar.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R8Lh8z_QIuBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dotenv support\n",
        "!pip install -q python-dotenv\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load the .env file from current directory\n",
        "dotenv_path = \".env\"\n",
        "\n",
        "if os.path.exists(dotenv_path):\n",
        "    load_dotenv(dotenv_path)\n",
        "    print(\"✅ Environment variables loaded.\\n\")\n",
        "\n",
        "    # Check specific keys (without printing sensitive values)\n",
        "    for key in ['OPENAI_API_KEY', 'AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY', 'S3_BUCKET_NAME', 'IMAGES_DIR']:\n",
        "        val = os.getenv(key)\n",
        "        if val:\n",
        "            print(f\"{key}: ✅ Loaded\")\n",
        "        else:\n",
        "            print(f\"{key}: ❌ Missing or not set in .env\")\n",
        "else:\n",
        "    print(\"❌ `.env` file not found. Please upload it via the file browser.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAgfERmQPJle",
        "outputId": "60d3f2d7-e5a9-43b2-d4a2-0c4c11830418"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Environment variables loaded.\n",
            "\n",
            "OPENAI_API_KEY: ✅ Loaded\n",
            "AWS_ACCESS_KEY_ID: ✅ Loaded\n",
            "AWS_SECRET_ACCESS_KEY: ✅ Loaded\n",
            "S3_BUCKET_NAME: ✅ Loaded\n",
            "IMAGES_DIR: ✅ Loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🏠 Photo Metadata AI - AWS Rekognition Photo Categorizer\n",
        "\n",
        "## 📋 What It Does\n",
        "\n",
        "Automatically analyzes and categorizes real estate photos using AWS Rekognition AI. Uploads images from local folders to S3, then uses AI to detect objects and scenes, organizing them into categories like kitchen, bedroom, bathroom, etc.\n",
        "\n",
        "## 🎯 Categories\n",
        "\n",
        "- 🍳 **Kitchen**: Appliances, cabinets, countertops\n",
        "- 🛏️ **Bedroom**: Beds, furniture, sleeping areas  \n",
        "- 🚿 **Bathroom**: Toilets, showers, sinks, mirrors\n",
        "- 🛋️ **Living Room**: Sofas, TVs, fireplaces\n",
        "- 🍽️ **Dining Room**: Dining tables, chairs\n",
        "- 🏠 **Exterior**: Building exteriors, architecture\n",
        "- 🚗 **Garage**: Cars, vehicles, parking\n",
        "- 💼 **Office**: Desks, computers, work areas\n",
        "- 👕 **Laundry**: Washing machines, dryers\n",
        "- 🪜 **Stairs**: Staircases, railings\n",
        "- 👔 **Closet**: Wardrobes, clothing storage\n",
        "- 🏊 **Pool**: Swimming pools, water features\n",
        "- 🌿 **Balcony**: Terraces, patios, decks\n",
        "- 📦 **Other**: Unmatched items\n",
        "\n",
        "## 📁 Required Folder Structure\n",
        "\n",
        "```\n",
        "images/\n",
        "├── property-123/\n",
        "│   ├── kitchen1.jpg\n",
        "│   ├── bedroom1.jpg\n",
        "│   └── bathroom1.jpg\n",
        "├── property-456/\n",
        "│   ├── exterior1.jpg\n",
        "│   └── garage1.jpg\n",
        "└── property-789/\n",
        "    ├── office1.jpg\n",
        "    └── dining1.jpg\n",
        "```\n",
        "\n",
        "## 🔧 Usage Options\n",
        "\n",
        "When you run `photo-categorizer`, you'll get three options:\n",
        "\n",
        "1. **📤 Upload Only**: Upload images from local folder to S3\n",
        "2. **🔍 Categorize Only**: Process existing images in S3  \n",
        "3. **🚀 Upload + Categorize**: Complete workflow (recommended)\n",
        "\n",
        "## 📊 Results\n",
        "\n",
        "- ✅ **Organized Images**: Sorted into category folders in S3\n",
        "- 📈 **JSON Reports**: Detailed analysis with confidence scores\n",
        "- 📋 **Summary**: Breakdown of images by category\n",
        "- 🔍 **Labels**: Top detected objects for each image\n",
        "\n",
        "## 🛠️ Requirements\n",
        "\n",
        "- ✅ AWS Account with S3 and Rekognition access\n",
        "- ✅ AWS credentials configured\n",
        "- ✅ S3 bucket created\n",
        "- ✅ Images in proper folder structure\n",
        "\n",
        "## 🔐 Security Notes\n",
        "\n",
        "- ⚠️ Never commit AWS credentials to version control\n",
        "- 🔒 Use IAM roles with minimal required permissions"
      ],
      "metadata": {
        "id": "O2606Vs8t2kL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Read the path from the environment variable\n",
        "images_dir = os.getenv(\"IMAGES_DIR\")\n",
        "\n",
        "# Check if the variable is set\n",
        "if images_dir is None:\n",
        "    raise ValueError(\"Environment variable 'IMAGES_DIR' is not set.\")\n",
        "\n",
        "# Create\n"
      ],
      "metadata": {
        "id": "oaRyIzZTvieS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "KOLPerIPwAxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the tool from GitHub\n",
        "!pip install git+https://github.com/elephant-xyz/photo-meta-data-ai.git\n",
        "\n",
        "\n",
        "\n",
        "# Run the photo categorizer\n",
        "!photo-categorizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sop-vyQlt4Bx",
        "outputId": "596b9d13-cacf-4ffc-bd29-dd96b1004183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/elephant-xyz/photo-meta-data-ai.git\n",
            "  Cloning https://github.com/elephant-xyz/photo-meta-data-ai.git to /tmp/pip-req-build-1us8mi2n\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/elephant-xyz/photo-meta-data-ai.git /tmp/pip-req-build-1us8mi2n\n",
            "  Resolved https://github.com/elephant-xyz/photo-meta-data-ai.git to commit 42d7a47582b841fb3b3f69f9b1d68b2507436c93\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: boto3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from photo-metadata-ai==1.0.0) (1.39.10)\n",
            "Requirement already satisfied: botocore>=1.29.0 in /usr/local/lib/python3.11/dist-packages (from photo-metadata-ai==1.0.0) (1.39.10)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3>=1.26.0->photo-metadata-ai==1.0.0) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from boto3>=1.26.0->photo-metadata-ai==1.0.0) (0.13.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore>=1.29.0->photo-metadata-ai==1.0.0) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore>=1.29.0->photo-metadata-ai==1.0.0) (2.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.29.0->photo-metadata-ai==1.0.0) (1.17.0)\n",
            "AWS Rekognition Photo Categorizer\n",
            "=============================================\n",
            "Target S3 Bucket: photo-metadata-ai/\n",
            "=============================================\n",
            "\n",
            "1. Authenticating with AWS...\n",
            "✓ AWS S3 authentication successful\n",
            "✓ AWS Rekognition client initialized\n",
            "✓ Using S3 bucket: photo-metadata-ai/\n",
            "\n",
            "2. Select property to process:\n",
            "Enter property ID (or 'all' to process all properties):\n",
            "Property ID: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir images"
      ],
      "metadata": {
        "id": "BUHluqwUvM_Y"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}